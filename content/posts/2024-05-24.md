+++
title = "2024-05-24"
date = 2024-05-24

[taxonomies]
authors = ["Lu√≠sa Coelho"]
+++

---

Today is Friday, day 145 of 366 (39.61%). We're in week 21 of 52 (40.38%).

## Planning

What I am going to do today:

- [x] [Make requested changes to the translation script](https://github.com/OmnicodeSolutions/blog/pull/184#pullrequestreview-2074109013)
- [ ] Finish the bot that'll help me with the report

## Activities executed

Today I made some changes Mauricio requested on the translation script; he also made some changes himself, and it's pretty much done.

I also tried to finish up the report using LLMs but got a bit lost in the process. I got confused about whether I really needed an embedding for this since I'm not doing a search/recommendation system, and started researching more to see if I could find something similar to what I'm trying to do. I came across [this Langchain documentation](https://python.langchain.com/v0.2/docs/tutorials/graph/) about question-answering applications

After thinking about what I actually need for a while, I asked ChatGPT for help and it gave me a sample code that doesn't work and a step-by-step:

```
Step 1: Extract Data from Zola Blog
First, extract the content of your blog posts. Assuming you have access to the markdown files, you can read them into your script. If they are hosted online, you may need to scrape the data or use an API if available.

Step 2: Preprocess Data
Preprocess the extracted data to make it suitable for querying and summarizing. This might include cleaning the text, organizing it by date, and separating different sections of the entries.

Step 3: Set Up LangChain and ChromaDB
LangChain will help you manage the interaction with language models, and ChromaDB can be used for storing and querying your blog content. You can index your daily entries in ChromaDB to allow efficient retrieval.

Step 4: Query the Data and Generate Report Sections
Use OpenAI's GPT-4 to generate the content for each section of the report. You can create prompts that summarize the activities, methodologies, and conclusions based on your blog entries.
```

The first three steps are pretty much already covered in my current code, and step 4 is exactly where I stopped yesterday and what got me into this mess, but apparently I can use the embeddings instead of a database, which is nice; I just need to figure out how to and I don't think ChatGPT's code helps me in that matter.
